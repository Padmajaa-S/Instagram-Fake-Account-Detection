{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA \n",
    "def standardize_data(X):\n",
    "    mean = np.mean(X, axis=0)\n",
    "    std_dev = np.std(X, axis=0)\n",
    "    X_scaled = (X - mean) / std_dev\n",
    "    return X_scaled, mean, std_dev\n",
    "\n",
    "X_train_scaled, mean_train, std_dev_train = standardize_data(x_train)\n",
    "X_test_scaled = (x_test - mean_train) / std_dev_train\n",
    "\n",
    "cov_matrix = np.cov(X_train_scaled.T)\n",
    "\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "\n",
    "k = 5 \n",
    "top_indices = np.argsort(eigenvalues)[::-1][:k]\n",
    "top_eigenvectors = eigenvectors[:, top_indices]\n",
    "\n",
    "X_train_pca = X_train_scaled.dot(top_eigenvectors)\n",
    "X_test_pca = X_test_scaled.dot(top_eigenvectors)\n",
    "\n",
    "naive_bayes = GaussianNB()\n",
    "naive_bayes.fit(X_train_pca, y_train)\n",
    "\n",
    "y_pred = naive_bayes.predict(X_test_pca)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy in naive bayes:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decision tree\n",
    "\n",
    "k = 10 \n",
    "accuracy_scores = []\n",
    "fold_size = len(X_train_pca) // k\n",
    "for i in range(k):\n",
    "    start_idx = i * fold_size\n",
    "    end_idx = start_idx + fold_size\n",
    "    X_val_fold = X_train_pca[start_idx:end_idx]\n",
    "    y_val_fold = y_train[start_idx:end_idx]\n",
    "    \n",
    "    X_train_fold = np.concatenate([X_train_pca[:start_idx], X_train_pca[end_idx:]], axis=0)\n",
    "    y_train_fold = np.concatenate([y_train[:start_idx], y_train[end_idx:]], axis=0)\n",
    "    \n",
    "    decision_tree = DecisionTreeClassifier()\n",
    "    decision_tree.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    y_pred_fold = decision_tree.predict(X_val_fold)\n",
    "\n",
    "    accuracy_fold = accuracy_score(y_val_fold, y_pred_fold)\n",
    "    accuracy_scores.append(accuracy_fold)\n",
    "\n",
    "average_accuracy = np.mean(accuracy_scores)\n",
    "print(\"Average Accuracy:\", average_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "random_forest = RandomForestClassifier()\n",
    "random_forest.fit(X_train_pca, y_train)\n",
    "rf_y_pred = random_forest.predict(X_test_pca)\n",
    "rf_accuracy = accuracy_score(y_test, rf_y_pred)\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
    "# Gradient Boosting\n",
    "gradient_boosting = GradientBoostingClassifier()\n",
    "gradient_boosting.fit(X_train_pca, y_train)\n",
    "gb_y_pred = gradient_boosting.predict(X_test_pca)\n",
    "gb_accuracy = accuracy_score(y_test, gb_y_pred)\n",
    "print(\"Gradient Boosting Accuracy:\", gb_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BOOSTING TECHNIQUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "\n",
    "gb_grid_search = GridSearchCV(GradientBoostingClassifier(), param_grid=gb_param_grid, cv=5)\n",
    "gb_grid_search.fit(x_train, y_train)\n",
    "\n",
    "best_gb_model = gb_grid_search.best_estimator_\n",
    "\n",
    "dump(best_gb_model, 'best_gradient_boosting_model.joblib')\n",
    "\n",
    "gb_y_pred = best_gb_model.predict(x_train)\n",
    "gb_accuracy = accuracy_score(y_train, gb_y_pred)\n",
    "print(\"Gradient Boosting Accuracy using GridSearchCV:\", gb_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_gb_model = load('best_gradient_boosting_model.joblib')\n",
    "new_data = pd.read_csv(r'C:\\Users\\Padmajaa\\OneDrive - SSN Trust\\4th sem\\ML lab\\PROJECT\\flask\\profile_info.csv')  # Replace 'your_data_for_prediction.csv' with the path to your CSV file\n",
    "\n",
    "X_new = new_data  \n",
    "predictions = best_gb_model.predict(X_new)\n",
    "print(\"Predictions:\")\n",
    "for pred in predictions:\n",
    "    print(\"Fake\" if pred == 1 else \"Not Fake\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
